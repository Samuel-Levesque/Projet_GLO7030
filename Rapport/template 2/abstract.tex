On souhaite réaliser un projet \emph{end-to-end} en traitement d'images pour couvrir toutes les étapes d'un projet en analyse prédictive tout en se familiarisant avec les solutions d'infonuagique et de travailler avec des données massives.

En utilisant des transformations de données sur nos intrants vectoriels, on arrive à arrimer notre interface graphique avec nos données d'entraînement. 

Aussi, en utilisant une technique d'échantillonnage ciblé, on obtient des gains de précision de 2\% par rapport à un entraînement standard sur notre architecture \emph{ResNet18}. 

Avec un modèle par ensemble simple et nos deux classificateurs \emph{ResNet18}, on obtient une \emph{Mean Average Precision} sur 3 prédictions de 85.66\% et les prédictions du modèle semblent naturelles pour l'humain même lorsqu'elles ne correpondent pas à l'étiquette réelle de l'image qu'on tente de classifier.

L'utilisation de l'évolution temporelle des dessins et classificateurs moins corrélés et plus spécialisés dans notre modèle par ensemble nous permettrait d'augmenter les performances globales de notre modèle prédictif et de se rapprocher de l'état de l'art qui fournit des performances avoisinants les 95\% en MAP@3.