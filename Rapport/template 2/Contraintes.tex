Une quantité de données aussi importante crée des enjeux et problèmes importants dans l'entraînement du réseau. On présente ici les enjeux principaux qui nous amènent à tester différentes manières d'entraînement.


\subsection{Enjeux de mémoire}

Pour pouvoir utiliser des réseaux de neurones à convolution, il faut utiliser des données étant sous forme d'image. Étant donné la quantité massive de données, il ne semble pas optimal de transformer toutes les données du format csv en images directement avant l'entraînement. Pour pallier à ce problème et pour pouvoir utiliser des réseaux pré-entraîné , on transforme le format csv des traits de crayon au moment où on charge les données dans le modèle.

\subsection{Enjeux de performance}

La quantité massive de données ne nous permet pas de faire des epochs traditionnelles. En effet, avec les moyens de calculs que nous utilisons (\emph{Google Colab}) , une seule epoch peut prendre environ 1 mois en calculant 24h/24.

Pour cette même raison, on ne peut pas tester une grande quantité d'hyperparamètres. Il faut se limiter un ensemble d'hyperparamètres pour chacun des modèles que l'on veut tester.


\subsection{Enjeux d'une application réelle}

La mise en place d'une application concrète nous amène également quelques contraintes supplémentaires. L'application créée nous fait perdre l'information temporelle des traits de crayons puisque la sortie de l'application est une image de format png. On ne peut donc pas utiliser l'ordre dans lequel les traits ont été dessinés par l'utilisateur. Il nous est donc impossible d'utiliser différents canaux pour simuler l'évolution temporelle du dessin





